{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import os\n",
    "paths = []\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "index_name = \"final1\"\n",
    "pc = Pinecone(api_key=\"a7bdaea1-66dd-4525-ae19-6ab0191ff9cb\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=200  \n",
    ")\n",
    "tot_chunks = []\n",
    "def make_chunks(text) :\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_context(ques) :\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    ques_emb = model.encode(ques)\n",
    "    DB_response = index.query(\n",
    "        vector=ques_emb.tolist(),\n",
    "        top_k=3,\n",
    "        include_values=True\n",
    "    )\n",
    "\n",
    "    cont = \"\"\n",
    "    for i in range(len(DB_response['matches'])) :\n",
    "        cont += tot_chunks[int(DB_response['matches'][i]['id'][3:])-1]\n",
    "    return cont\n",
    "\n",
    "def extract_pdf(path) :\n",
    "    pdf_path = path\n",
    "    reader = PdfReader(pdf_path)\n",
    "\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "\n",
    "    print(extracted_text)\n",
    "    return extracted_text\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index-cpy.html')\n",
    "\n",
    "@app.route('/upload_files', methods=['POST'])\n",
    "def upload_file():\n",
    "    global tot_chunks\n",
    "    files = request.files.getlist('files')\n",
    "    for file in files:\n",
    "        file_path = file.filename\n",
    "        file.save(file_path)\n",
    "        paths.append(file_path)\n",
    "        print(f\"Uploaded file path: {file_path}\")\n",
    "\n",
    "    extracted = \"\"\n",
    "    for path in paths: \n",
    "        extracted += extract_pdf(path)\n",
    "    tot_chunks = make_chunks(extracted)\n",
    "    tot_embeddings = model.encode(tot_chunks)\n",
    "\n",
    "    tot_vectors = []\n",
    "    for i, vec in enumerate(tot_embeddings):\n",
    "        tot_vectors.append({\"id\": f\"vec{i+1}\", \"values\": vec.tolist()})\n",
    "    try :\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws', \n",
    "                region='us-east-1'\n",
    "            ) \n",
    "        ) \n",
    "    except :\n",
    "        pass\n",
    "    index = pc.Index(index_name)\n",
    "    index.upsert( tot_vectors )\n",
    "    return \"Success !\"\n",
    "\n",
    "\n",
    "@app.route('/send', methods=['POST'])\n",
    "def send_text():\n",
    "    query = request.json['text']\n",
    "    context = get_context(query)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context : {context} , Analyse and understand the above context completely and answer the below query , Query : {query}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "    return response_text\n",
    "\n",
    "@app.route('/clear', methods=['POST'])\n",
    "def clearDB():\n",
    "    try :\n",
    "        pc.delete_index(index_name)\n",
    "\n",
    "    except :\n",
    "        pass\n",
    "    print(\"DELETED !!\")\n",
    "    return \"Success !\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tot_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
