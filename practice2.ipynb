{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(path) :\n",
    "    pdf_path = path\n",
    "    reader = PdfReader(pdf_path)\n",
    "\n",
    "    # Initialize an empty string to store the extracted text\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "\n",
    "    print(extracted_text)\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Set your desired chunk size\n",
    "    chunk_overlap=200  # Set your desired chunk overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(text) :\n",
    "    return text_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone : 7812026222\n",
      "Sri Eshwar College of Engineering \n",
      "Government Boys Higher Secondary School\n",
      "Government Boys Higher Secondary SchoolGitHub LinkedIn \n",
      "Machine Learning Intern - Prodigy InfoTech                                                                                                          2024\n",
      "Machine Learning (ML) internship , Developed and implemented ML models, conducted training  and\n",
      "validation, and analyzed performance metrics. Proficient in data preprocessing, model deployment, and  \n",
      "effective communication within interdisciplinary teams.\n",
      "MERN Stack - RVTechlearn                                                                                                                                    2024\n",
      "Interned on MERN stack, gaining hands-on experience in full-stack web development. Developed user-friendly\n",
      "interfaces with React.js, built RESTful APIs with Node.js and Express.js, and managed MongoDB databases.\n",
      "Collaborated on version control with Git and contributed to problem-solving and optimization efforts.\n",
      "Data Science Intern - MokSa.AI                                                                                                                              2023\n",
      "Managed and analyzed large video datasets, extracting meaningful insights and ensuring data quality.\n",
      "Collaborated with the data science team to develop, train, and evaluate machine learning models       using\n",
      "Python and scikit-learn, specifically tailored to video data.Email : rajesh.d2022ai-ml@sece.ac.in\n",
      "EDUCATION\n",
      "INTERNSHIPRAJESH D\n",
      "2022 - 2026\n",
      "2020 - 2022   \n",
      "2019 - 2020\n",
      "PROJECTS\n",
      ":    Rating - 1640+ | Top 20.56 % in the World | profile\n",
      ":    Rating - 1000+ | profile\n",
      ":    Secured 2nd prize with a cash amount of 2000 at KEC\n",
      ":    Secured 1st prize with a cash amount of 3000 at SECE\n",
      ":    Secured 3rd prize in the Project leap at SECE\n",
      ":    Finalists of National Level HackFest Conducted by PSG\n",
      ":    Secured 1st prize with a cash prize of Rs.15,000  at IITM-Research Park ,GUVI .\n",
      ":    Secured 1st  prize with a cash amount of 2000 at SECE\n",
      ":    Secured 2nd prize with a cash amount of 1500 at SECEJAVA Programming - Beginner to Master | Udemy \n",
      "SQL Certifications from Hackerrank | Hackerrank \n",
      "Mastering Data Structure and Algorithms Using C and C++ | Udemy\n",
      "Leetcode\n",
      "Codechef\n",
      "AI Hackathon\n",
      "InnoFest\n",
      "Project Leap\n",
      "PSG iTechHackFest\n",
      "Hackerruptâ€™24\n",
      "Design Derby\n",
      "Web Warfare\n",
      " SKILLSCERTIFICATIONS\n",
      "PROGRAMMING and ACHIEVEMENTS2024\n",
      "2023\n",
      "2023SenseAI - AI Enhanced Learning companion                                                                                                           2023\n",
      "Versatile OFFLINE learning tool offering summarization, translation, image generation, doubt clarification\n",
      "using LLM, and AI-generated topic-specific question answering. Revolutionizes learning by providing\n",
      "comprehensive educational resources offline, ensuring accessibility  without internet connectivity.\n",
      "Tech stack:  LLM , OpenCV , NLP , Flask , Flutter Anomaly Detection using DL                                                                                                                                    2024\n",
      "Developed anomaly detection model utilizing CNN and LSTM architectures, trained on UCF Crime Dataset.\n",
      "Accurately identifies anomalies such as shoplifting and assault in video surveillance footage. Integrated spatial\n",
      "analysis and temporal modeling to enhance sensitivity to anomalous activities, strengthening security measures\n",
      "across diverse environments.\n",
      "Tech stack:  DL , Streamlit  , DSAI powered Video Annotation Tool                                                                                                                           2024\n",
      "Executed consultancy work for a company, developing an AI-powered video annotator to streamline video\n",
      "annotation for dataset creation and labeling tasks. Leveraged YOLO v8 object detection to facilitate efficient\n",
      "annotation of videos, providing annotated video clips and JSON data. Automated annotation process,\n",
      "significantly enhancing productivity and accuracy in dataset creation .\n",
      "Tech stack:  OpenCV , JavaScript , HTML , CSS  \n",
      "B.E. CSE(AI&ML) \n",
      "HSC\n",
      "SSLC CGPA : 8.57 (upto 2nd sem)\n",
      "87%\n",
      "87%\n",
      "Languages - C | Python | JAVA | HTML | CSS | JavaScript \n",
      "Core - Machine Learning | Deep Learning | NLP | DBMS | OpenCV | Data Science\n",
      "Web Technologies - HTML | CSS | JavaScript | React  \n",
      "Framework -  React | NodeJS | ExpressJS | Flask | Flutter | LangChain\n",
      "DBMS - MySQL , MongoDB\n",
      "Others  - Data Structures and Algorithms | OOPS | Operating System | LLM\n",
      "Sentence embeddings:\n",
      "[[-0.07152447 -0.00950384  0.0571324  ... -0.07294437 -0.01838481\n",
      "   0.00719859]\n",
      " [-0.07617094 -0.02801255  0.02093662 ... -0.07764331 -0.03551965\n",
      "   0.01464766]\n",
      " [-0.09418571 -0.05012426 -0.03791192 ... -0.1156038  -0.0498855\n",
      "  -0.00154813]\n",
      " [-0.02981125 -0.08867536  0.01401224 ...  0.02139681 -0.0441049\n",
      "   0.0067581 ]\n",
      " [-0.05132081 -0.04488523  0.0042937  ... -0.01585809  0.0240377\n",
      "  -0.05843462]\n",
      " [-0.06263851 -0.11686604 -0.00105503 ... -0.08600146  0.06376727\n",
      "   0.03185724]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences into embeddings\n",
    "extracted_txt = extract_pdf(\"C:/Users/Rajesh/Downloads/Rajesh_Res5.pdf (9).pdf\")\n",
    "chunks = make_chunks(extracted_txt)\n",
    "embeddings = model.encode(chunks)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(embeddings)\n",
    "vectors = []\n",
    "for i, vec in enumerate(embeddings):\n",
    "    vectors.append({\"id\": f\"vec{i+1}\", \"values\": vec.tolist()})\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"a7bdaea1-66dd-4525-ae19-6ab0191ff9cb\")\n",
    "index_name = \"test1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mindex_name\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index_name' is not defined"
     ]
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws', \n",
    "        region='us-east-1'\n",
    "    ) \n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "# index.upsert( vectors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(ques) :\n",
    "    ques_emb = model.encode(ques)\n",
    "    DB_response = index.query(\n",
    "        vector=ques_emb.tolist(),\n",
    "        top_k=3,\n",
    "        include_values=True\n",
    "    )\n",
    "\n",
    "    cont = \"\"\n",
    "    for i in range(len(DB_response['matches'])) :\n",
    "        cont += chunks[int(DB_response['matches'][i]['id'][3:])-1]\n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query) :\n",
    "    context = get_context(query)\n",
    "    # print(context)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context : {context} , Analyse and understand the above context completely and answer the below query , Query : {query}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat(\"number of interns completed ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "paths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n",
      "Flask 2.2.2\n",
      "Werkzeug 2.2.2\n"
     ]
    }
   ],
   "source": [
    "!flask --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file2():\n",
    "    print(\"HIII\")\n",
    "    if 'file' not in request.files:\n",
    "        return 'No file part'\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return 'No selected file'\n",
    "    if file:\n",
    "        filename = file.filename\n",
    "        file.save(os.path.join('C:/NLP/DocChat', filename))\n",
    "        paths.append(filename)\n",
    "        print(paths)\n",
    "        return 'File uploaded successfully'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/May/2024 20:14:36] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 20:14:57] \"POST /upload_files HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file path: AI_Syllabus.pdf\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import os\n",
    "paths = []\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "index_name = \"final1\"\n",
    "pc = Pinecone(api_key=\"a7bdaea1-66dd-4525-ae19-6ab0191ff9cb\")\n",
    "index = pc.Index(index_name)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Set your desired chunk size\n",
    "    chunk_overlap=200  # Set your desired chunk overlap\n",
    ")\n",
    "tot_chunks = []\n",
    "def make_chunks(text) :\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_context(ques) :\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    ques_emb = model.encode(ques)\n",
    "    DB_response = index.query(\n",
    "        vector=ques_emb.tolist(),\n",
    "        top_k=3,\n",
    "        include_values=True\n",
    "    )\n",
    "\n",
    "    cont = \"\"\n",
    "    for i in range(len(DB_response['matches'])) :\n",
    "        cont += tot_chunks[int(DB_response['matches'][i]['id'][3:])-1]\n",
    "    return cont\n",
    "\n",
    "def extract_pdf(path) :\n",
    "    pdf_path = path\n",
    "    reader = PdfReader(pdf_path)\n",
    "\n",
    "    # Initialize an empty string to store the extracted text\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "\n",
    "    print(extracted_text)\n",
    "    return extracted_text\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index-cpy.html')\n",
    "\n",
    "@app.route('/upload_files', methods=['POST'])\n",
    "def upload_file():\n",
    "    global tot_chunks\n",
    "    files = request.files.getlist('files')\n",
    "    for file in files:\n",
    "        file_path = file.filename\n",
    "        file.save(file_path)\n",
    "        paths.append(file_path)\n",
    "        print(f\"Uploaded file path: {file_path}\")\n",
    "\n",
    "    extracted = \"\"\n",
    "    for path in paths: \n",
    "        extracted += extract_pdf(path)\n",
    "    tot_chunks = make_chunks(extracted)\n",
    "    tot_embeddings = model.encode(tot_chunks)\n",
    "\n",
    "    tot_vectors = []\n",
    "    for i, vec in enumerate(tot_embeddings):\n",
    "        tot_vectors.append({\"id\": f\"vec{i+1}\", \"values\": vec.tolist()})\n",
    "\n",
    "    # pc.create_index(\n",
    "    #     name=index_name,\n",
    "    #     dimension=384,\n",
    "    #     metric=\"cosine\",\n",
    "    #     spec=ServerlessSpec(\n",
    "    #         cloud='aws', \n",
    "    #         region='us-east-1'\n",
    "    #     ) \n",
    "    # ) \n",
    "    index = pc.Index(index_name)\n",
    "    # index.upsert( tot_vectors )\n",
    "    return \"Success !\"\n",
    "\n",
    "\n",
    "@app.route('/send', methods=['POST'])\n",
    "def send_text():\n",
    "    query = request.json['text']\n",
    "    context = get_context(query)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context : {context} , Analyse and understand the above context completely and answer the below query , Query : {query}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/May/2024 22:39:22] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file path: Rajesh_Res5.pdf (10).pdf\n",
      "Phone : 7812026222\n",
      "Sri Eshwar College of Engineering \n",
      "Government Boys Higher Secondary School\n",
      "Government Boys Higher Secondary SchoolGitHub LinkedIn \n",
      "Machine Learning Intern - Prodigy InfoTech                                                                                                          2024\n",
      "Machine Learning (ML) internship , Developed and implemented ML models, conducted training  and\n",
      "validation, and analyzed performance metrics. Proficient in data preprocessing, model deployment, and  \n",
      "effective communication within interdisciplinary teams.\n",
      "MERN Stack - RVTechlearn                                                                                                                                    2024\n",
      "Interned on MERN stack, gaining hands-on experience in full-stack web development. Developed user-friendly\n",
      "interfaces with React.js, built RESTful APIs with Node.js and Express.js, and managed MongoDB databases.\n",
      "Collaborated on version control with Git and contributed to problem-solving and optimization efforts.\n",
      "Data Science Intern - MokSa.AI                                                                                                                              2023\n",
      "Managed and analyzed large video datasets, extracting meaningful insights and ensuring data quality.\n",
      "Collaborated with the data science team to develop, train, and evaluate machine learning models       using\n",
      "Python and scikit-learn, specifically tailored to video data.Email : rajesh.d2022ai-ml@sece.ac.in\n",
      "EDUCATION\n",
      "INTERNSHIPRAJESH D\n",
      "2022 - 2026\n",
      "2020 - 2022   \n",
      "2019 - 2020\n",
      "PROJECTS\n",
      ":    Rating - 1640+ | Top 20.56 % in the World | profile\n",
      ":    Rating - 1000+ | profile\n",
      ":    Secured 2nd prize with a cash amount of 2000 at KEC\n",
      ":    Secured 1st prize with a cash amount of 3000 at SECE\n",
      ":    Secured 3rd prize in the Project leap at SECE\n",
      ":    Finalists of National Level HackFest Conducted by PSG\n",
      ":    Secured 1st prize with a cash prize of Rs.15,000  at IITM-Research Park ,GUVI .\n",
      ":    Secured 1st  prize with a cash amount of 2000 at SECE\n",
      ":    Secured 2nd prize with a cash amount of 1500 at SECEJAVA Programming - Beginner to Master | Udemy \n",
      "SQL Certifications from Hackerrank | Hackerrank \n",
      "Mastering Data Structure and Algorithms Using C and C++ | Udemy\n",
      "Leetcode\n",
      "Codechef\n",
      "AI Hackathon\n",
      "InnoFest\n",
      "Project Leap\n",
      "PSG iTechHackFest\n",
      "Hackerruptâ€™24\n",
      "Design Derby\n",
      "Web Warfare\n",
      " SKILLSCERTIFICATIONS\n",
      "PROGRAMMING and ACHIEVEMENTS2024\n",
      "2023\n",
      "2023SenseAI - AI Enhanced Learning companion                                                                                                           2023\n",
      "Versatile OFFLINE learning tool offering summarization, translation, image generation, doubt clarification\n",
      "using LLM, and AI-generated topic-specific question answering. Revolutionizes learning by providing\n",
      "comprehensive educational resources offline, ensuring accessibility  without internet connectivity.\n",
      "Tech stack:  LLM , OpenCV , NLP , Flask , Flutter Anomaly Detection using DL                                                                                                                                    2024\n",
      "Developed anomaly detection model utilizing CNN and LSTM architectures, trained on UCF Crime Dataset.\n",
      "Accurately identifies anomalies such as shoplifting and assault in video surveillance footage. Integrated spatial\n",
      "analysis and temporal modeling to enhance sensitivity to anomalous activities, strengthening security measures\n",
      "across diverse environments.\n",
      "Tech stack:  DL , Streamlit  , DSAI powered Video Annotation Tool                                                                                                                           2024\n",
      "Executed consultancy work for a company, developing an AI-powered video annotator to streamline video\n",
      "annotation for dataset creation and labeling tasks. Leveraged YOLO v8 object detection to facilitate efficient\n",
      "annotation of videos, providing annotated video clips and JSON data. Automated annotation process,\n",
      "significantly enhancing productivity and accuracy in dataset creation .\n",
      "Tech stack:  OpenCV , JavaScript , HTML , CSS  \n",
      "B.E. CSE(AI&ML) \n",
      "HSC\n",
      "SSLC CGPA : 8.57 (upto 2nd sem)\n",
      "87%\n",
      "87%\n",
      "Languages - C | Python | JAVA | HTML | CSS | JavaScript \n",
      "Core - Machine Learning | Deep Learning | NLP | DBMS | OpenCV | Data Science\n",
      "Web Technologies - HTML | CSS | JavaScript | React  \n",
      "Framework -  React | NodeJS | ExpressJS | Flask | Flutter | LangChain\n",
      "DBMS - MySQL , MongoDB\n",
      "Others  - Data Structures and Algorithms | OOPS | Operating System | LLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/May/2024 22:39:33] \"POST /upload_files HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 22:40:25] \"POST /send HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
